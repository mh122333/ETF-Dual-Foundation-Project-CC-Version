{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Experiment 3: Baseline + Forecast + Context Features\n",
        "\n",
        "This notebook extends Experiment 2 by adding context asset forecast features from market-wide ETFs (SPY, QQQ).\n",
        "\n",
        "**New Features Added:**\n",
        "- Context asset forecasts (SPY, QQQ) at multiple horizons\n",
        "- Relative features: asset vs market forecast comparisons\n",
        "- Market regime indicators from context forecasts\n",
        "\n",
        "**Hypothesis:**\n",
        "Market context provides additional signal for individual asset prediction. When the market is expected to rally, individual assets may behave differently.\n",
        "\n",
        "**Prerequisites:**\n",
        "- Run Experiment 0/1 first to generate labeled dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# CONFIGURATION\n",
        "# ============================================================\n",
        "\n",
        "CONFIG = {\n",
        "    # Symbols to train on\n",
        "    \"symbols_to_train\": [\"SPY\"],\n",
        "    \n",
        "    # Context symbols for market features\n",
        "    \"context_symbols\": [\"SPY\"],  # Can add \"QQQ\" for more context\n",
        "    \n",
        "    # Data limits\n",
        "    \"max_rows_per_symbol\": 6500,\n",
        "    \n",
        "    # Label parameters\n",
        "    \"label_col\": \"label\",\n",
        "    \"vertical_barrier_bars\": 26,\n",
        "    \n",
        "    # Split parameters\n",
        "    \"embargo_bars\": 26,\n",
        "    \"tune_window\": 260,\n",
        "    \"test_window\": 520,\n",
        "    \"min_train_size\": 2000,\n",
        "    \n",
        "    # AutoGluon Tabular\n",
        "    \"time_limit_sec\": 1200,\n",
        "    \"presets\": \"best_quality\",\n",
        "    \n",
        "    # Time Series\n",
        "    \"ts_prediction_length\": 26,\n",
        "    \"ts_presets\": \"chronos_small\",\n",
        "    \"ts_train_lookback_years\": 5.0,\n",
        "    \n",
        "    # Feature parameters\n",
        "    \"feature_set\": \"small\",\n",
        "    \"forecast_prefix\": \"fc_\",\n",
        "    \"include_relative\": True,  # Include relative features (asset vs context)\n",
        "    \n",
        "    # Reproducibility\n",
        "    \"random_seed\": 42,\n",
        "    \n",
        "    # Force options\n",
        "    \"force_data_refresh\": False,\n",
        "    \"force_ts_retrain\": False,\n",
        "    \"force_forecast_regenerate\": False,\n",
        "}\n",
        "\n",
        "print(\"Configuration:\")\n",
        "for k, v in CONFIG.items():\n",
        "    print(f\"  {k}: {v}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "print(\"Installing dependencies...\")\n",
        "!pip install -q autogluon.tabular[tabarena] || pip install -q autogluon.tabular[all]\n",
        "!pip install -q autogluon.timeseries[chronos-openvino]\n",
        "!pip install -q pandas numpy pyarrow scikit-learn pytz alpaca-py\n",
        "print(\"\\nInstallation complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clone/update repository\n",
        "import os\n",
        "\n",
        "REPO_URL = \"https://github.com/mh122333/ETF-Dual-Foundation-Project-CC-Version.git\"\n",
        "REPO_DIR = \"/content/ETF-Dual-Foundation-Project-CC-Version\"\n",
        "BRANCH = \"claude/build-pipeline-sanity-exp-iVs65\"\n",
        "\n",
        "if os.path.exists(REPO_DIR):\n",
        "    print(\"Repository exists, updating...\")\n",
        "    %cd {REPO_DIR}\n",
        "    !git fetch origin\n",
        "    !git checkout {BRANCH}\n",
        "    !git pull origin {BRANCH}\n",
        "else:\n",
        "    print(\"Cloning repository...\")\n",
        "    !git clone {REPO_URL} {REPO_DIR}\n",
        "    %cd {REPO_DIR}\n",
        "    !git checkout {BRANCH}\n",
        "\n",
        "print(f\"\\nOn branch: {BRANCH}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Add src to path and set random seeds\n",
        "import sys\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "sys.path.insert(0, '/content/ETF-Dual-Foundation-Project-CC-Version/src')\n",
        "\n",
        "random.seed(CONFIG[\"random_seed\"])\n",
        "np.random.seed(CONFIG[\"random_seed\"])\n",
        "\n",
        "print(f\"Random seed set to: {CONFIG['random_seed']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Imports\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "import json\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Project imports\n",
        "from etf_pipeline.utils.paths import get_drive_paths, ensure_dirs, get_labeled_dataset_path\n",
        "from etf_pipeline.splits.purged_walkforward import (\n",
        "    create_single_split,\n",
        "    apply_split_to_dataframe,\n",
        "    validate_split_no_leakage,\n",
        ")\n",
        "from etf_pipeline.models.tabular_baseline import (\n",
        "    train_tabular_baseline,\n",
        "    predict_tabular,\n",
        ")\n",
        "from etf_pipeline.metrics.classification import (\n",
        "    compute_all_metrics,\n",
        "    save_metrics,\n",
        "    print_metrics_summary,\n",
        ")\n",
        "\n",
        "# Time series imports\n",
        "from etf_pipeline.timeseries.dataset import prepare_ts_training_data\n",
        "from etf_pipeline.timeseries.train import load_or_train_timeseries_predictor\n",
        "from etf_pipeline.timeseries.rolling_predict import load_or_generate_forecasts\n",
        "\n",
        "# Feature imports\n",
        "from etf_pipeline.features.forecast_features import (\n",
        "    merge_forecast_features,\n",
        "    get_forecast_feature_names,\n",
        "    FEATURE_SET_CONFIGS,\n",
        ")\n",
        "from etf_pipeline.features.context_features import (\n",
        "    add_context_features,\n",
        "    compute_relative_features,\n",
        ")\n",
        "from etf_pipeline.features.baseline import get_feature_columns\n",
        "\n",
        "print(\"Imports successful!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create output directories\n",
        "paths = ensure_dirs()\n",
        "print(\"Output directories:\")\n",
        "for name, path in paths.items():\n",
        "    print(f\"  {name}: {path}\")\n",
        "\n",
        "# Generate run ID\n",
        "run_timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "symbols_str = \"_\".join(CONFIG[\"symbols_to_train\"])\n",
        "RUN_ID = f\"exp3_{symbols_str}_{run_timestamp}\"\n",
        "print(f\"\\nRun ID: {RUN_ID}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load labeled dataset\n",
        "labeled_dataset_path = get_labeled_dataset_path()\n",
        "print(f\"Loading labeled dataset from: {labeled_dataset_path}\")\n",
        "\n",
        "if not labeled_dataset_path.exists():\n",
        "    raise FileNotFoundError(f\"Labeled dataset not found. Run Experiment 0/1 first.\")\n",
        "\n",
        "full_df = pd.read_parquet(labeled_dataset_path)\n",
        "print(f\"Loaded {len(full_df)} rows\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load raw bars\n",
        "bars_path = paths[\"raw\"] / \"bars_30min.parquet\"\n",
        "\n",
        "if bars_path.exists():\n",
        "    print(f\"Loading cached bars from: {bars_path}\")\n",
        "    bars_df = pd.read_parquet(bars_path)\n",
        "else:\n",
        "    print(\"Fetching bars from Alpaca...\")\n",
        "    from google.colab import userdata\n",
        "    from alpaca.data.historical import StockHistoricalDataClient\n",
        "    import pytz\n",
        "    from etf_pipeline.data.alpaca import load_all_symbols\n",
        "    \n",
        "    api_key = userdata.get(\"PAPER_KEY\")\n",
        "    api_secret = userdata.get(\"PAPER_SEC\")\n",
        "    client = StockHistoricalDataClient(api_key, api_secret)\n",
        "    \n",
        "    eastern = pytz.timezone(\"US/Eastern\")\n",
        "    start = eastern.localize(datetime(2019, 1, 1))\n",
        "    end = eastern.localize(datetime(2025, 12, 31))\n",
        "    \n",
        "    # Include context symbols\n",
        "    all_symbols = list(set(CONFIG[\"symbols_to_train\"] + CONFIG[\"context_symbols\"] + [\"SPY\", \"QQQ\"]))\n",
        "    bars_df = load_all_symbols(client, all_symbols, start, end, cache=True)\n",
        "    bars_df.to_parquet(bars_path)\n",
        "    print(f\"Saved bars to: {bars_path}\")\n",
        "\n",
        "print(f\"Bars shape: {bars_df.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Generate Forecasts for Target and Context Symbols"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define horizons\n",
        "feature_set_config = FEATURE_SET_CONFIGS[CONFIG[\"feature_set\"]]\n",
        "horizons = feature_set_config[\"horizons\"]\n",
        "print(f\"Feature set: {CONFIG['feature_set']}\")\n",
        "print(f\"Horizons: {horizons}\")\n",
        "\n",
        "# All symbols that need forecasts (target + context)\n",
        "all_forecast_symbols = list(set(CONFIG[\"symbols_to_train\"] + CONFIG[\"context_symbols\"]))\n",
        "print(f\"\\nSymbols needing forecasts: {all_forecast_symbols}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate forecasts for all symbols\n",
        "all_forecasts = {}\n",
        "\n",
        "# Get decision timestamps from the first target symbol\n",
        "first_target = CONFIG[\"symbols_to_train\"][0]\n",
        "if isinstance(full_df.index, pd.MultiIndex):\n",
        "    target_labeled = full_df.loc[first_target].copy()\n",
        "else:\n",
        "    target_labeled = full_df[full_df[\"symbol\"] == first_target].copy()\n",
        "target_labeled = target_labeled.sort_index()\n",
        "\n",
        "max_rows = CONFIG[\"max_rows_per_symbol\"]\n",
        "if max_rows and len(target_labeled) > max_rows:\n",
        "    target_labeled = target_labeled.iloc[-max_rows:]\n",
        "\n",
        "decision_timestamps = target_labeled.index.tolist()\n",
        "print(f\"Decision timestamps: {len(decision_timestamps)}\")\n",
        "\n",
        "for symbol in all_forecast_symbols:\n",
        "    print(f\"\\n{'=' * 60}\")\n",
        "    print(f\"GENERATING FORECASTS FOR: {symbol}\")\n",
        "    print(f\"{'=' * 60}\")\n",
        "    \n",
        "    # Get symbol bars\n",
        "    if isinstance(bars_df.index, pd.MultiIndex):\n",
        "        symbol_bars = bars_df.loc[symbol].copy()\n",
        "    else:\n",
        "        symbol_bars = bars_df[bars_df[\"symbol\"] == symbol].copy()\n",
        "    symbol_bars = symbol_bars.sort_index()\n",
        "    \n",
        "    # Model path\n",
        "    ts_model_path = paths[\"models\"] / \"ts\" / symbol / f\"pred_len_{CONFIG['ts_prediction_length']}\"\n",
        "    ts_model_path.mkdir(parents=True, exist_ok=True)\n",
        "    \n",
        "    # Prepare training data\n",
        "    first_decision = decision_timestamps[0]\n",
        "    train_data = prepare_ts_training_data(\n",
        "        bars_df=symbol_bars,\n",
        "        symbols=[symbol],\n",
        "        train_end_timestamp=first_decision,\n",
        "        lookback_years=CONFIG[\"ts_train_lookback_years\"],\n",
        "    )\n",
        "    \n",
        "    # Train/load predictor\n",
        "    ts_predictor = load_or_train_timeseries_predictor(\n",
        "        train_data=train_data,\n",
        "        model_path=ts_model_path,\n",
        "        prediction_length=CONFIG[\"ts_prediction_length\"],\n",
        "        presets=CONFIG[\"ts_presets\"],\n",
        "        force_retrain=CONFIG[\"force_ts_retrain\"],\n",
        "    )\n",
        "    \n",
        "    # Generate forecasts\n",
        "    forecast_cache_path = paths[\"processed\"] / \"forecasts\" / symbol / f\"fc_{CONFIG['feature_set']}_{RUN_ID}.parquet\"\n",
        "    forecast_cache_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "    \n",
        "    forecasts = load_or_generate_forecasts(\n",
        "        predictor=ts_predictor,\n",
        "        bars_df=symbol_bars,\n",
        "        symbol=symbol,\n",
        "        decision_timestamps=decision_timestamps,\n",
        "        cache_path=forecast_cache_path,\n",
        "        horizons=horizons,\n",
        "        force_regenerate=CONFIG[\"force_forecast_regenerate\"],\n",
        "    )\n",
        "    \n",
        "    print(f\"Forecasts shape: {forecasts.shape}\")\n",
        "    all_forecasts[symbol] = forecasts\n",
        "\n",
        "print(\"\\nForecast generation complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Merge All Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Merge all features for each target symbol\n",
        "merged_dfs = {}\n",
        "\n",
        "for symbol in CONFIG[\"symbols_to_train\"]:\n",
        "    print(f\"\\nMerging features for {symbol}...\")\n",
        "    \n",
        "    # Get labeled data\n",
        "    if isinstance(full_df.index, pd.MultiIndex):\n",
        "        symbol_df = full_df.loc[symbol].copy()\n",
        "    else:\n",
        "        symbol_df = full_df[full_df[\"symbol\"] == symbol].copy()\n",
        "    symbol_df = symbol_df.sort_index()\n",
        "    \n",
        "    max_rows = CONFIG[\"max_rows_per_symbol\"]\n",
        "    if max_rows and len(symbol_df) > max_rows:\n",
        "        symbol_df = symbol_df.iloc[-max_rows:]\n",
        "    \n",
        "    # 1. Merge asset's own forecast features\n",
        "    merged = merge_forecast_features(\n",
        "        tabular_df=symbol_df,\n",
        "        forecasts_df=all_forecasts[symbol],\n",
        "        feature_set=CONFIG[\"feature_set\"],\n",
        "        prefix=CONFIG[\"forecast_prefix\"],\n",
        "    )\n",
        "    print(f\"  After own forecast features: {len(merged.columns)} columns\")\n",
        "    \n",
        "    # 2. Add context features\n",
        "    context_forecasts = {ctx: all_forecasts[ctx] for ctx in CONFIG[\"context_symbols\"]}\n",
        "    merged = add_context_features(\n",
        "        df=merged,\n",
        "        context_forecasts=context_forecasts,\n",
        "        target_symbol=symbol,\n",
        "        context_symbols=CONFIG[\"context_symbols\"],\n",
        "        feature_set=CONFIG[\"feature_set\"],\n",
        "        include_relative=CONFIG[\"include_relative\"],\n",
        "    )\n",
        "    print(f\"  After context features: {len(merged.columns)} columns\")\n",
        "    \n",
        "    merged_dfs[symbol] = merged\n",
        "\n",
        "print(\"\\nFeature merging complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define all feature columns\n",
        "baseline_features = get_feature_columns(True)\n",
        "forecast_features = get_forecast_feature_names(CONFIG[\"feature_set\"], CONFIG[\"forecast_prefix\"])\n",
        "\n",
        "# Context features\n",
        "context_features = []\n",
        "for ctx_sym in CONFIG[\"context_symbols\"]:\n",
        "    prefix = f\"ctx_{ctx_sym.lower()}_\"\n",
        "    for feat in feature_set_config[\"features\"]:\n",
        "        for h in horizons:\n",
        "            context_features.append(f\"{prefix}{feat}_{h}\")\n",
        "\n",
        "# Relative features\n",
        "relative_features = []\n",
        "if CONFIG[\"include_relative\"]:\n",
        "    for ctx_sym in CONFIG[\"context_symbols\"]:\n",
        "        for h in horizons:\n",
        "            relative_features.append(f\"rel_{ctx_sym.lower()}_mu_{h}\")\n",
        "            relative_features.append(f\"rel_{ctx_sym.lower()}_unc_{h}\")\n",
        "\n",
        "all_feature_cols = baseline_features + forecast_features + context_features + relative_features\n",
        "\n",
        "print(f\"Feature breakdown:\")\n",
        "print(f\"  Baseline: {len(baseline_features)}\")\n",
        "print(f\"  Own forecast: {len(forecast_features)}\")\n",
        "print(f\"  Context: {len(context_features)}\")\n",
        "print(f\"  Relative: {len(relative_features)}\")\n",
        "print(f\"  TOTAL: {len(all_feature_cols)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Train Tabular Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Store results\n",
        "all_results = {}\n",
        "\n",
        "for symbol in CONFIG[\"symbols_to_train\"]:\n",
        "    print(f\"\\n{'=' * 60}\")\n",
        "    print(f\"TRAINING MODEL FOR: {symbol}\")\n",
        "    print(f\"{'=' * 60}\")\n",
        "    \n",
        "    symbol_df = merged_dfs[symbol].copy()\n",
        "    \n",
        "    # Filter to available features\n",
        "    available_features = [f for f in all_feature_cols if f in symbol_df.columns]\n",
        "    missing_features = [f for f in all_feature_cols if f not in symbol_df.columns]\n",
        "    if missing_features:\n",
        "        print(f\"Warning: Missing features: {missing_features[:5]}...\")\n",
        "    \n",
        "    # Clean data\n",
        "    required_cols = available_features + [CONFIG[\"label_col\"]]\n",
        "    symbol_df_clean = symbol_df.dropna(subset=required_cols).copy()\n",
        "    \n",
        "    print(f\"\\nData after cleaning: {len(symbol_df_clean)} rows (dropped {len(symbol_df) - len(symbol_df_clean)})\")\n",
        "    \n",
        "    symbol_df_clean = symbol_df_clean.reset_index(drop=False)\n",
        "    if \"timestamp\" not in symbol_df_clean.columns and \"index\" in symbol_df_clean.columns:\n",
        "        symbol_df_clean = symbol_df_clean.rename(columns={\"index\": \"timestamp\"})\n",
        "    \n",
        "    # Create split\n",
        "    try:\n",
        "        split = create_single_split(\n",
        "            n_samples=len(symbol_df_clean),\n",
        "            vertical_barrier_bars=CONFIG[\"vertical_barrier_bars\"],\n",
        "            embargo_bars=CONFIG[\"embargo_bars\"],\n",
        "            tune_window=CONFIG[\"tune_window\"],\n",
        "            test_window=CONFIG[\"test_window\"],\n",
        "            min_train_size=CONFIG[\"min_train_size\"],\n",
        "        )\n",
        "    except ValueError as e:\n",
        "        print(f\"ERROR: {e}\")\n",
        "        continue\n",
        "    \n",
        "    is_valid = validate_split_no_leakage(split, CONFIG[\"vertical_barrier_bars\"])\n",
        "    print(f\"Split valid: {is_valid}\")\n",
        "    \n",
        "    train_df, tune_df, test_df = apply_split_to_dataframe(symbol_df_clean, split)\n",
        "    print(f\"Split: Train={len(train_df)}, Tune={len(tune_df)}, Test={len(test_df)}\")\n",
        "    \n",
        "    # Train\n",
        "    model_path = paths[\"models\"] / \"exp3\" / symbol / RUN_ID\n",
        "    model_path.mkdir(parents=True, exist_ok=True)\n",
        "    \n",
        "    print(f\"\\nTraining with {len(available_features)} features...\")\n",
        "    \n",
        "    predictor = train_tabular_baseline(\n",
        "        train_df=train_df,\n",
        "        tune_df=tune_df,\n",
        "        feature_cols=available_features,\n",
        "        label_col=CONFIG[\"label_col\"],\n",
        "        model_path=model_path,\n",
        "        time_limit=CONFIG[\"time_limit_sec\"],\n",
        "        presets=CONFIG[\"presets\"],\n",
        "        random_seed=CONFIG[\"random_seed\"],\n",
        "        verbosity=2,\n",
        "    )\n",
        "    print(\"Training complete!\")\n",
        "    \n",
        "    # Predictions\n",
        "    predictions_df = predict_tabular(predictor, test_df, available_features)\n",
        "    predictions_df[\"actual_label\"] = test_df[CONFIG[\"label_col\"]].values\n",
        "    if \"timestamp\" in test_df.columns:\n",
        "        predictions_df[\"timestamp\"] = test_df[\"timestamp\"].values\n",
        "    \n",
        "    run_dir = paths[\"runs\"] / f\"exp3_{RUN_ID}\"\n",
        "    run_dir.mkdir(parents=True, exist_ok=True)\n",
        "    predictions_path = run_dir / f\"predictions_{symbol}.parquet\"\n",
        "    predictions_df.to_parquet(predictions_path)\n",
        "    \n",
        "    # Metrics\n",
        "    metrics = compute_all_metrics(\n",
        "        y_true=test_df[CONFIG[\"label_col\"]],\n",
        "        y_pred=predictions_df[\"predicted_label\"],\n",
        "        y_train=train_df[CONFIG[\"label_col\"]],\n",
        "        y_tune=tune_df[CONFIG[\"label_col\"]],\n",
        "    )\n",
        "    \n",
        "    metrics[\"run_info\"] = {\n",
        "        \"run_id\": RUN_ID,\n",
        "        \"experiment\": \"exp3\",\n",
        "        \"symbol\": symbol,\n",
        "        \"timestamp\": datetime.now().isoformat(),\n",
        "        \"config\": CONFIG,\n",
        "        \"feature_count\": len(available_features),\n",
        "        \"context_symbols\": CONFIG[\"context_symbols\"],\n",
        "    }\n",
        "    \n",
        "    metrics_path = run_dir / f\"metrics_{symbol}.json\"\n",
        "    save_metrics(metrics, metrics_path)\n",
        "    \n",
        "    print_metrics_summary(metrics)\n",
        "    \n",
        "    all_results[symbol] = {\n",
        "        \"metrics\": metrics,\n",
        "        \"predictor\": predictor,\n",
        "        \"model_path\": model_path,\n",
        "    }\n",
        "\n",
        "print(f\"\\n{'=' * 60}\")\n",
        "print(\"ALL SYMBOLS COMPLETE!\")\n",
        "print(f\"{'=' * 60}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"\\n{'=' * 60}\")\n",
        "print(\"EXPERIMENT 3 SUMMARY\")\n",
        "print(f\"{'=' * 60}\")\n",
        "\n",
        "print(f\"\\nRun ID: {RUN_ID}\")\n",
        "print(f\"Symbols trained: {list(all_results.keys())}\")\n",
        "print(f\"Context symbols: {CONFIG['context_symbols']}\")\n",
        "print(f\"Feature set: {CONFIG['feature_set']}\")\n",
        "print(f\"Total features: {len(all_feature_cols)}\")\n",
        "\n",
        "print(f\"\\nPerformance Summary:\")\n",
        "print(\"-\" * 50)\n",
        "print(f\"{'Symbol':<10} {'Accuracy':>10} {'Bal Acc':>10} {'Macro F1':>10}\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "for symbol, result in all_results.items():\n",
        "    m = result[\"metrics\"][\"classification\"]\n",
        "    print(f\"{symbol:<10} {m['accuracy']:>10.4f} {m['balanced_accuracy']:>10.4f} {m['macro_f1']:>10.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare with previous experiments\n",
        "print(\"\\nComparison with Previous Experiments:\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "for exp_name in [\"exp1\", \"exp2\"]:\n",
        "    exp_runs = list((paths[\"runs\"]).glob(f\"{exp_name}_*\"))\n",
        "    if exp_runs:\n",
        "        latest_run = sorted(exp_runs)[-1]\n",
        "        print(f\"\\n{exp_name.upper()} (latest: {latest_run.name}):\")\n",
        "        \n",
        "        for symbol in all_results.keys():\n",
        "            prev_metrics_path = latest_run / f\"metrics_{symbol}.json\"\n",
        "            if prev_metrics_path.exists():\n",
        "                with open(prev_metrics_path) as f:\n",
        "                    prev_metrics = json.load(f)\n",
        "                \n",
        "                prev_ba = prev_metrics[\"classification\"][\"balanced_accuracy\"]\n",
        "                curr_ba = all_results[symbol][\"metrics\"][\"classification\"][\"balanced_accuracy\"]\n",
        "                diff = curr_ba - prev_ba\n",
        "                \n",
        "                print(f\"  {symbol}: {prev_ba:.4f} -> {curr_ba:.4f} ({diff:+.4f})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "**Experiment 3 Complete!**\n",
        "\n",
        "Next: Experiment 4 adds forecast error/coverage features (model health monitoring)."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
