{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Experiment 5: Ablation Studies\n",
        "\n",
        "This notebook runs systematic ablation studies to understand the contribution of each feature group and configuration choice.\n",
        "\n",
        "**Ablations:**\n",
        "1. **Feature Set Size**: small vs medium vs large forecast features\n",
        "2. **Context Symbols**: With vs without SPY/QQQ context\n",
        "3. **Error Features**: With vs without forecast error monitoring\n",
        "4. **Model Presets**: medium_quality vs best_quality\n",
        "5. **Cross-Learning**: Per-symbol vs pooled TS models (if applicable)\n",
        "\n",
        "**Output:**\n",
        "- Results table comparing all configurations\n",
        "- Statistical significance tests where applicable\n",
        "- Feature importance analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# ABLATION CONFIGURATION\n",
        "# ============================================================\n",
        "\n",
        "# Base configuration shared across all ablations\n",
        "BASE_CONFIG = {\n",
        "    \"symbols_to_train\": [\"SPY\"],\n",
        "    \"max_rows_per_symbol\": 6500,\n",
        "    \"label_col\": \"label\",\n",
        "    \"vertical_barrier_bars\": 26,\n",
        "    \"embargo_bars\": 26,\n",
        "    \"tune_window\": 260,\n",
        "    \"test_window\": 520,\n",
        "    \"min_train_size\": 2000,\n",
        "    \"time_limit_sec\": 600,  # Shorter for ablations\n",
        "    \"ts_prediction_length\": 26,\n",
        "    \"ts_presets\": \"chronos_small\",\n",
        "    \"ts_train_lookback_years\": 5.0,\n",
        "    \"random_seed\": 42,\n",
        "}\n",
        "\n",
        "# Ablation configurations\n",
        "ABLATIONS = [\n",
        "    # 1. Baseline only (Exp 1 equivalent)\n",
        "    {\n",
        "        \"name\": \"baseline_only\",\n",
        "        \"description\": \"Baseline features only (no forecast)\",\n",
        "        \"include_forecast\": False,\n",
        "        \"include_context\": False,\n",
        "        \"include_error\": False,\n",
        "        \"feature_set\": \"small\",\n",
        "        \"presets\": \"best_quality\",\n",
        "    },\n",
        "    # 2. Small feature set\n",
        "    {\n",
        "        \"name\": \"small_features\",\n",
        "        \"description\": \"Small feature set (2 horizons)\",\n",
        "        \"include_forecast\": True,\n",
        "        \"include_context\": True,\n",
        "        \"include_error\": True,\n",
        "        \"feature_set\": \"small\",\n",
        "        \"context_symbols\": [\"SPY\"],\n",
        "        \"presets\": \"best_quality\",\n",
        "    },\n",
        "    # 3. Medium feature set\n",
        "    {\n",
        "        \"name\": \"medium_features\",\n",
        "        \"description\": \"Medium feature set (4 horizons)\",\n",
        "        \"include_forecast\": True,\n",
        "        \"include_context\": True,\n",
        "        \"include_error\": True,\n",
        "        \"feature_set\": \"medium\",\n",
        "        \"context_symbols\": [\"SPY\"],\n",
        "        \"presets\": \"best_quality\",\n",
        "    },\n",
        "    # 4. No context features\n",
        "    {\n",
        "        \"name\": \"no_context\",\n",
        "        \"description\": \"Full features without context\",\n",
        "        \"include_forecast\": True,\n",
        "        \"include_context\": False,\n",
        "        \"include_error\": True,\n",
        "        \"feature_set\": \"small\",\n",
        "        \"presets\": \"best_quality\",\n",
        "    },\n",
        "    # 5. No error features\n",
        "    {\n",
        "        \"name\": \"no_error_features\",\n",
        "        \"description\": \"Full features without error monitoring\",\n",
        "        \"include_forecast\": True,\n",
        "        \"include_context\": True,\n",
        "        \"include_error\": False,\n",
        "        \"feature_set\": \"small\",\n",
        "        \"context_symbols\": [\"SPY\"],\n",
        "        \"presets\": \"best_quality\",\n",
        "    },\n",
        "    # 6. Medium quality preset\n",
        "    {\n",
        "        \"name\": \"medium_quality_preset\",\n",
        "        \"description\": \"Full features with medium_quality preset\",\n",
        "        \"include_forecast\": True,\n",
        "        \"include_context\": True,\n",
        "        \"include_error\": True,\n",
        "        \"feature_set\": \"small\",\n",
        "        \"context_symbols\": [\"SPY\"],\n",
        "        \"presets\": \"medium_quality\",\n",
        "    },\n",
        "]\n",
        "\n",
        "print(f\"Base configuration:\")\n",
        "for k, v in BASE_CONFIG.items():\n",
        "    print(f\"  {k}: {v}\")\n",
        "\n",
        "print(f\"\\nAblations to run: {len(ABLATIONS)}\")\n",
        "for abl in ABLATIONS:\n",
        "    print(f\"  - {abl['name']}: {abl['description']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "print(\"Installing dependencies...\")\n",
        "!pip install -q autogluon.tabular[tabarena] || pip install -q autogluon.tabular[all]\n",
        "!pip install -q autogluon.timeseries[chronos-openvino]\n",
        "!pip install -q pandas numpy pyarrow scikit-learn pytz alpaca-py\n",
        "print(\"\\nInstallation complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clone/update repository\n",
        "import os\n",
        "\n",
        "REPO_URL = \"https://github.com/mh122333/ETF-Dual-Foundation-Project-CC-Version.git\"\n",
        "REPO_DIR = \"/content/ETF-Dual-Foundation-Project-CC-Version\"\n",
        "BRANCH = \"claude/build-pipeline-sanity-exp-iVs65\"\n",
        "\n",
        "if os.path.exists(REPO_DIR):\n",
        "    %cd {REPO_DIR}\n",
        "    !git fetch origin && git checkout {BRANCH} && git pull origin {BRANCH}\n",
        "else:\n",
        "    !git clone {REPO_URL} {REPO_DIR}\n",
        "    %cd {REPO_DIR}\n",
        "    !git checkout {BRANCH}\n",
        "\n",
        "print(f\"\\nOn branch: {BRANCH}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup\n",
        "import sys\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "sys.path.insert(0, '/content/ETF-Dual-Foundation-Project-CC-Version/src')\n",
        "\n",
        "random.seed(BASE_CONFIG[\"random_seed\"])\n",
        "np.random.seed(BASE_CONFIG[\"random_seed\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Imports\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from etf_pipeline.utils.paths import ensure_dirs, get_labeled_dataset_path\n",
        "from etf_pipeline.splits.purged_walkforward import (\n",
        "    create_single_split,\n",
        "    apply_split_to_dataframe,\n",
        "    validate_split_no_leakage,\n",
        ")\n",
        "from etf_pipeline.models.tabular_baseline import (\n",
        "    train_tabular_baseline,\n",
        "    predict_tabular,\n",
        ")\n",
        "from etf_pipeline.metrics.classification import (\n",
        "    compute_all_metrics,\n",
        "    save_metrics,\n",
        ")\n",
        "\n",
        "from etf_pipeline.timeseries.dataset import prepare_ts_training_data\n",
        "from etf_pipeline.timeseries.train import load_or_train_timeseries_predictor\n",
        "from etf_pipeline.timeseries.rolling_predict import load_or_generate_forecasts\n",
        "\n",
        "from etf_pipeline.features.forecast_features import (\n",
        "    merge_forecast_features,\n",
        "    get_forecast_feature_names,\n",
        "    FEATURE_SET_CONFIGS,\n",
        ")\n",
        "from etf_pipeline.features.context_features import add_context_features\n",
        "from etf_pipeline.features.forecast_error_features import (\n",
        "    compute_forecast_errors,\n",
        "    compute_rolling_error_features,\n",
        "    get_error_feature_names,\n",
        ")\n",
        "from etf_pipeline.features.baseline import get_feature_columns\n",
        "\n",
        "print(\"Imports successful!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create output directories\n",
        "paths = ensure_dirs()\n",
        "\n",
        "run_timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "RUN_ID = f\"exp5_ablations_{run_timestamp}\"\n",
        "print(f\"Run ID: {RUN_ID}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load labeled dataset\n",
        "labeled_dataset_path = get_labeled_dataset_path()\n",
        "if not labeled_dataset_path.exists():\n",
        "    raise FileNotFoundError(\"Labeled dataset not found. Run Experiment 0/1 first.\")\n",
        "\n",
        "full_df = pd.read_parquet(labeled_dataset_path)\n",
        "print(f\"Loaded {len(full_df)} rows\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load raw bars\n",
        "bars_path = paths[\"raw\"] / \"bars_30min.parquet\"\n",
        "\n",
        "if bars_path.exists():\n",
        "    bars_df = pd.read_parquet(bars_path)\n",
        "else:\n",
        "    from google.colab import userdata\n",
        "    from alpaca.data.historical import StockHistoricalDataClient\n",
        "    import pytz\n",
        "    from etf_pipeline.data.alpaca import load_all_symbols\n",
        "    \n",
        "    api_key = userdata.get(\"PAPER_KEY\")\n",
        "    api_secret = userdata.get(\"PAPER_SEC\")\n",
        "    client = StockHistoricalDataClient(api_key, api_secret)\n",
        "    \n",
        "    eastern = pytz.timezone(\"US/Eastern\")\n",
        "    start = eastern.localize(datetime(2019, 1, 1))\n",
        "    end = eastern.localize(datetime(2025, 12, 31))\n",
        "    \n",
        "    all_symbols = [\"SPY\", \"QQQ\", \"IWM\", \"AAPL\", \"MSFT\"]\n",
        "    bars_df = load_all_symbols(client, all_symbols, start, end, cache=True)\n",
        "    bars_df.to_parquet(bars_path)\n",
        "\n",
        "print(f\"Bars shape: {bars_df.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Helper Functions for Ablations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_single_ablation(ablation_config, base_config, full_df, bars_df, paths, run_id):\n",
        "    \"\"\"\n",
        "    Run a single ablation configuration.\n",
        "    \n",
        "    Returns:\n",
        "        Dictionary with results for this ablation.\n",
        "    \"\"\"\n",
        "    name = ablation_config[\"name\"]\n",
        "    print(f\"\\n{'=' * 60}\")\n",
        "    print(f\"ABLATION: {name}\")\n",
        "    print(f\"Description: {ablation_config['description']}\")\n",
        "    print(f\"{'=' * 60}\")\n",
        "    \n",
        "    # Merge configs\n",
        "    config = {**base_config, **ablation_config}\n",
        "    \n",
        "    results = {\"name\": name, \"config\": ablation_config, \"symbols\": {}}\n",
        "    \n",
        "    for symbol in config[\"symbols_to_train\"]:\n",
        "        print(f\"\\nProcessing {symbol}...\")\n",
        "        \n",
        "        # Get data for symbol\n",
        "        if isinstance(full_df.index, pd.MultiIndex):\n",
        "            symbol_df = full_df.loc[symbol].copy()\n",
        "        else:\n",
        "            symbol_df = full_df[full_df[\"symbol\"] == symbol].copy()\n",
        "        symbol_df = symbol_df.sort_index()\n",
        "        \n",
        "        max_rows = config[\"max_rows_per_symbol\"]\n",
        "        if max_rows and len(symbol_df) > max_rows:\n",
        "            symbol_df = symbol_df.iloc[-max_rows:]\n",
        "        \n",
        "        # Get decision timestamps\n",
        "        decision_timestamps = symbol_df.index.tolist()\n",
        "        \n",
        "        # Build feature set based on config\n",
        "        feature_cols = get_feature_columns(True)  # Always include baseline\n",
        "        \n",
        "        if config.get(\"include_forecast\", False):\n",
        "            feature_set = config.get(\"feature_set\", \"small\")\n",
        "            horizons = FEATURE_SET_CONFIGS[feature_set][\"horizons\"]\n",
        "            \n",
        "            # Get symbol bars\n",
        "            if isinstance(bars_df.index, pd.MultiIndex):\n",
        "                symbol_bars = bars_df.loc[symbol].copy()\n",
        "            else:\n",
        "                symbol_bars = bars_df[bars_df[\"symbol\"] == symbol].copy()\n",
        "            symbol_bars = symbol_bars.sort_index()\n",
        "            \n",
        "            # Train/load TS predictor and generate forecasts\n",
        "            ts_model_path = paths[\"models\"] / \"ts\" / symbol / f\"pred_len_{config['ts_prediction_length']}\"\n",
        "            ts_model_path.mkdir(parents=True, exist_ok=True)\n",
        "            \n",
        "            first_decision = decision_timestamps[0]\n",
        "            train_data = prepare_ts_training_data(\n",
        "                bars_df=symbol_bars,\n",
        "                symbols=[symbol],\n",
        "                train_end_timestamp=first_decision,\n",
        "                lookback_years=config[\"ts_train_lookback_years\"],\n",
        "            )\n",
        "            \n",
        "            ts_predictor = load_or_train_timeseries_predictor(\n",
        "                train_data=train_data,\n",
        "                model_path=ts_model_path,\n",
        "                prediction_length=config[\"ts_prediction_length\"],\n",
        "                presets=config[\"ts_presets\"],\n",
        "                force_retrain=False,\n",
        "            )\n",
        "            \n",
        "            forecast_cache_path = paths[\"processed\"] / \"forecasts\" / symbol / f\"fc_{feature_set}_{run_id}.parquet\"\n",
        "            forecast_cache_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "            \n",
        "            forecasts = load_or_generate_forecasts(\n",
        "                predictor=ts_predictor,\n",
        "                bars_df=symbol_bars,\n",
        "                symbol=symbol,\n",
        "                decision_timestamps=decision_timestamps,\n",
        "                cache_path=forecast_cache_path,\n",
        "                horizons=horizons,\n",
        "                force_regenerate=False,\n",
        "            )\n",
        "            \n",
        "            # Merge forecast features\n",
        "            symbol_df = merge_forecast_features(\n",
        "                tabular_df=symbol_df,\n",
        "                forecasts_df=forecasts,\n",
        "                feature_set=feature_set,\n",
        "                prefix=\"fc_\",\n",
        "            )\n",
        "            feature_cols.extend(get_forecast_feature_names(feature_set, \"fc_\"))\n",
        "            \n",
        "            # Context features\n",
        "            if config.get(\"include_context\", False):\n",
        "                context_symbols = config.get(\"context_symbols\", [\"SPY\"])\n",
        "                context_forecasts = {}\n",
        "                \n",
        "                for ctx_sym in context_symbols:\n",
        "                    if ctx_sym == symbol:\n",
        "                        context_forecasts[ctx_sym] = forecasts\n",
        "                    else:\n",
        "                        # Generate forecasts for context symbol\n",
        "                        if isinstance(bars_df.index, pd.MultiIndex):\n",
        "                            ctx_bars = bars_df.loc[ctx_sym].copy()\n",
        "                        else:\n",
        "                            ctx_bars = bars_df[bars_df[\"symbol\"] == ctx_sym].copy()\n",
        "                        ctx_bars = ctx_bars.sort_index()\n",
        "                        \n",
        "                        ctx_model_path = paths[\"models\"] / \"ts\" / ctx_sym / f\"pred_len_{config['ts_prediction_length']}\"\n",
        "                        ctx_model_path.mkdir(parents=True, exist_ok=True)\n",
        "                        \n",
        "                        ctx_train_data = prepare_ts_training_data(\n",
        "                            bars_df=ctx_bars,\n",
        "                            symbols=[ctx_sym],\n",
        "                            train_end_timestamp=first_decision,\n",
        "                            lookback_years=config[\"ts_train_lookback_years\"],\n",
        "                        )\n",
        "                        \n",
        "                        ctx_predictor = load_or_train_timeseries_predictor(\n",
        "                            train_data=ctx_train_data,\n",
        "                            model_path=ctx_model_path,\n",
        "                            prediction_length=config[\"ts_prediction_length\"],\n",
        "                            presets=config[\"ts_presets\"],\n",
        "                            force_retrain=False,\n",
        "                        )\n",
        "                        \n",
        "                        ctx_cache_path = paths[\"processed\"] / \"forecasts\" / ctx_sym / f\"fc_{feature_set}_{run_id}.parquet\"\n",
        "                        ctx_cache_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "                        \n",
        "                        ctx_forecasts = load_or_generate_forecasts(\n",
        "                            predictor=ctx_predictor,\n",
        "                            bars_df=ctx_bars,\n",
        "                            symbol=ctx_sym,\n",
        "                            decision_timestamps=decision_timestamps,\n",
        "                            cache_path=ctx_cache_path,\n",
        "                            horizons=horizons,\n",
        "                            force_regenerate=False,\n",
        "                        )\n",
        "                        context_forecasts[ctx_sym] = ctx_forecasts\n",
        "                \n",
        "                symbol_df = add_context_features(\n",
        "                    df=symbol_df,\n",
        "                    context_forecasts=context_forecasts,\n",
        "                    target_symbol=symbol,\n",
        "                    context_symbols=context_symbols,\n",
        "                    feature_set=feature_set,\n",
        "                    include_relative=True,\n",
        "                )\n",
        "                \n",
        "                # Add context feature names\n",
        "                for ctx_sym in context_symbols:\n",
        "                    prefix = f\"ctx_{ctx_sym.lower()}_\"\n",
        "                    for feat in FEATURE_SET_CONFIGS[feature_set][\"features\"]:\n",
        "                        for h in horizons:\n",
        "                            feature_cols.append(f\"{prefix}{feat}_{h}\")\n",
        "                    for h in horizons:\n",
        "                        feature_cols.append(f\"rel_{ctx_sym.lower()}_mu_{h}\")\n",
        "                        feature_cols.append(f\"rel_{ctx_sym.lower()}_unc_{h}\")\n",
        "            \n",
        "            # Error features\n",
        "            if config.get(\"include_error\", False):\n",
        "                # Compute realized returns\n",
        "                realized_returns = []\n",
        "                for ts in symbol_df.index:\n",
        "                    try:\n",
        "                        ts_loc = symbol_bars.index.get_loc(ts)\n",
        "                        future_loc = ts_loc + 1\n",
        "                        if future_loc < len(symbol_bars):\n",
        "                            ret = np.log(symbol_bars.iloc[future_loc][\"close\"] / symbol_bars.iloc[ts_loc][\"close\"])\n",
        "                        else:\n",
        "                            ret = np.nan\n",
        "                    except (KeyError, IndexError):\n",
        "                        ret = np.nan\n",
        "                    realized_returns.append(ret)\n",
        "                \n",
        "                realized_returns = pd.Series(realized_returns, index=symbol_df.index)\n",
        "                \n",
        "                if \"mu_1\" in forecasts.columns:\n",
        "                    error_df = compute_forecast_errors(\n",
        "                        realized_returns=realized_returns,\n",
        "                        forecast_mu=forecasts[\"mu_1\"],\n",
        "                        forecast_q10=forecasts.get(\"q10_1\", pd.Series(np.nan, index=forecasts.index)),\n",
        "                        forecast_q90=forecasts.get(\"q90_1\", pd.Series(np.nan, index=forecasts.index)),\n",
        "                    )\n",
        "                    \n",
        "                    rolling_errors = compute_rolling_error_features(error_df)\n",
        "                    rolling_errors.columns = [f\"err_{c}\" for c in rolling_errors.columns]\n",
        "                    symbol_df = symbol_df.join(rolling_errors, how=\"left\")\n",
        "                    feature_cols.extend(get_error_feature_names(\"err_\", 20, 20, 50))\n",
        "        \n",
        "        # Filter to available features\n",
        "        available_features = [f for f in feature_cols if f in symbol_df.columns]\n",
        "        print(f\"  Features: {len(available_features)}\")\n",
        "        \n",
        "        # Clean and prepare data\n",
        "        required_cols = available_features + [config[\"label_col\"]]\n",
        "        symbol_df_clean = symbol_df.dropna(subset=required_cols).copy()\n",
        "        print(f\"  Rows: {len(symbol_df_clean)}\")\n",
        "        \n",
        "        symbol_df_clean = symbol_df_clean.reset_index(drop=False)\n",
        "        if \"timestamp\" not in symbol_df_clean.columns and \"index\" in symbol_df_clean.columns:\n",
        "            symbol_df_clean = symbol_df_clean.rename(columns={\"index\": \"timestamp\"})\n",
        "        \n",
        "        # Create split\n",
        "        try:\n",
        "            split = create_single_split(\n",
        "                n_samples=len(symbol_df_clean),\n",
        "                vertical_barrier_bars=config[\"vertical_barrier_bars\"],\n",
        "                embargo_bars=config[\"embargo_bars\"],\n",
        "                tune_window=config[\"tune_window\"],\n",
        "                test_window=config[\"test_window\"],\n",
        "                min_train_size=config[\"min_train_size\"],\n",
        "            )\n",
        "        except ValueError as e:\n",
        "            print(f\"  ERROR: {e}\")\n",
        "            results[\"symbols\"][symbol] = {\"error\": str(e)}\n",
        "            continue\n",
        "        \n",
        "        train_df, tune_df, test_df = apply_split_to_dataframe(symbol_df_clean, split)\n",
        "        print(f\"  Split: Train={len(train_df)}, Tune={len(tune_df)}, Test={len(test_df)}\")\n",
        "        \n",
        "        # Train model\n",
        "        model_path = paths[\"models\"] / \"exp5\" / name / symbol / run_id\n",
        "        model_path.mkdir(parents=True, exist_ok=True)\n",
        "        \n",
        "        presets = config.get(\"presets\", \"best_quality\")\n",
        "        print(f\"  Training ({presets})...\")\n",
        "        \n",
        "        predictor = train_tabular_baseline(\n",
        "            train_df=train_df,\n",
        "            tune_df=tune_df,\n",
        "            feature_cols=available_features,\n",
        "            label_col=config[\"label_col\"],\n",
        "            model_path=model_path,\n",
        "            time_limit=config[\"time_limit_sec\"],\n",
        "            presets=presets,\n",
        "            random_seed=config[\"random_seed\"],\n",
        "            verbosity=1,\n",
        "        )\n",
        "        \n",
        "        # Predictions\n",
        "        predictions_df = predict_tabular(predictor, test_df, available_features)\n",
        "        predictions_df[\"actual_label\"] = test_df[config[\"label_col\"]].values\n",
        "        \n",
        "        # Metrics\n",
        "        metrics = compute_all_metrics(\n",
        "            y_true=test_df[config[\"label_col\"]],\n",
        "            y_pred=predictions_df[\"predicted_label\"],\n",
        "            y_train=train_df[config[\"label_col\"]],\n",
        "            y_tune=tune_df[config[\"label_col\"]],\n",
        "        )\n",
        "        \n",
        "        print(f\"  Balanced Accuracy: {metrics['classification']['balanced_accuracy']:.4f}\")\n",
        "        \n",
        "        results[\"symbols\"][symbol] = {\n",
        "            \"metrics\": metrics,\n",
        "            \"feature_count\": len(available_features),\n",
        "            \"train_size\": len(train_df),\n",
        "            \"test_size\": len(test_df),\n",
        "        }\n",
        "    \n",
        "    return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Run All Ablations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run all ablations\n",
        "all_ablation_results = []\n",
        "\n",
        "for ablation in ABLATIONS:\n",
        "    try:\n",
        "        result = run_single_ablation(\n",
        "            ablation_config=ablation,\n",
        "            base_config=BASE_CONFIG,\n",
        "            full_df=full_df,\n",
        "            bars_df=bars_df,\n",
        "            paths=paths,\n",
        "            run_id=RUN_ID,\n",
        "        )\n",
        "        all_ablation_results.append(result)\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR in ablation {ablation['name']}: {e}\")\n",
        "        all_ablation_results.append({\n",
        "            \"name\": ablation[\"name\"],\n",
        "            \"error\": str(e),\n",
        "        })\n",
        "\n",
        "print(f\"\\n{'=' * 60}\")\n",
        "print(\"ALL ABLATIONS COMPLETE!\")\n",
        "print(f\"{'=' * 60}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Results Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build results table\n",
        "results_rows = []\n",
        "\n",
        "for result in all_ablation_results:\n",
        "    if \"error\" in result and \"symbols\" not in result:\n",
        "        continue\n",
        "    \n",
        "    name = result[\"name\"]\n",
        "    config = result.get(\"config\", {})\n",
        "    \n",
        "    for symbol, symbol_result in result.get(\"symbols\", {}).items():\n",
        "        if \"error\" in symbol_result:\n",
        "            continue\n",
        "        \n",
        "        metrics = symbol_result[\"metrics\"][\"classification\"]\n",
        "        \n",
        "        results_rows.append({\n",
        "            \"ablation\": name,\n",
        "            \"symbol\": symbol,\n",
        "            \"feature_count\": symbol_result[\"feature_count\"],\n",
        "            \"accuracy\": metrics[\"accuracy\"],\n",
        "            \"balanced_accuracy\": metrics[\"balanced_accuracy\"],\n",
        "            \"macro_f1\": metrics[\"macro_f1\"],\n",
        "            \"cohen_kappa\": metrics.get(\"cohen_kappa\", np.nan),\n",
        "            \"include_forecast\": config.get(\"include_forecast\", False),\n",
        "            \"include_context\": config.get(\"include_context\", False),\n",
        "            \"include_error\": config.get(\"include_error\", False),\n",
        "            \"feature_set\": config.get(\"feature_set\", \"small\"),\n",
        "            \"presets\": config.get(\"presets\", \"best_quality\"),\n",
        "        })\n",
        "\n",
        "results_df = pd.DataFrame(results_rows)\n",
        "print(\"\\nAblation Results:\")\n",
        "print(results_df.to_string(index=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Summary statistics\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"ABLATION SUMMARY\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "if not results_df.empty:\n",
        "    summary = results_df.groupby(\"ablation\").agg({\n",
        "        \"balanced_accuracy\": [\"mean\", \"std\"],\n",
        "        \"macro_f1\": [\"mean\", \"std\"],\n",
        "        \"feature_count\": \"mean\",\n",
        "    }).round(4)\n",
        "    \n",
        "    summary.columns = [\"_\".join(col).strip() for col in summary.columns.values]\n",
        "    summary = summary.sort_values(\"balanced_accuracy_mean\", ascending=False)\n",
        "    \n",
        "    print(\"\\nRanked by Balanced Accuracy:\")\n",
        "    print(summary.to_string())\n",
        "    \n",
        "    # Best configuration\n",
        "    best_idx = results_df[\"balanced_accuracy\"].idxmax()\n",
        "    best = results_df.loc[best_idx]\n",
        "    print(f\"\\nBest Configuration:\")\n",
        "    print(f\"  Ablation: {best['ablation']}\")\n",
        "    print(f\"  Symbol: {best['symbol']}\")\n",
        "    print(f\"  Balanced Accuracy: {best['balanced_accuracy']:.4f}\")\n",
        "    print(f\"  Feature Count: {best['feature_count']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save results\n",
        "run_dir = paths[\"runs\"] / f\"exp5_{RUN_ID}\"\n",
        "run_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Save results table\n",
        "results_path = run_dir / \"ablation_results.csv\"\n",
        "results_df.to_csv(results_path, index=False)\n",
        "print(f\"Results saved to: {results_path}\")\n",
        "\n",
        "# Save full results as JSON\n",
        "full_results_path = run_dir / \"ablation_full_results.json\"\n",
        "\n",
        "# Convert to serializable format\n",
        "serializable_results = []\n",
        "for result in all_ablation_results:\n",
        "    r = {\"name\": result[\"name\"]}\n",
        "    if \"config\" in result:\n",
        "        r[\"config\"] = result[\"config\"]\n",
        "    if \"error\" in result:\n",
        "        r[\"error\"] = result[\"error\"]\n",
        "    if \"symbols\" in result:\n",
        "        r[\"symbols\"] = {}\n",
        "        for sym, sym_result in result[\"symbols\"].items():\n",
        "            if \"error\" in sym_result:\n",
        "                r[\"symbols\"][sym] = {\"error\": sym_result[\"error\"]}\n",
        "            else:\n",
        "                r[\"symbols\"][sym] = {\n",
        "                    \"metrics\": sym_result[\"metrics\"],\n",
        "                    \"feature_count\": sym_result[\"feature_count\"],\n",
        "                    \"train_size\": sym_result[\"train_size\"],\n",
        "                    \"test_size\": sym_result[\"test_size\"],\n",
        "                }\n",
        "    serializable_results.append(r)\n",
        "\n",
        "with open(full_results_path, \"w\") as f:\n",
        "    json.dump(serializable_results, f, indent=2, default=str)\n",
        "print(f\"Full results saved to: {full_results_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Feature Ablation Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze impact of each feature group\n",
        "print(\"\\nFeature Group Impact Analysis:\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "if not results_df.empty:\n",
        "    # Baseline comparison\n",
        "    baseline_results = results_df[results_df[\"ablation\"] == \"baseline_only\"]\n",
        "    if not baseline_results.empty:\n",
        "        baseline_ba = baseline_results[\"balanced_accuracy\"].mean()\n",
        "        print(f\"\\nBaseline (no forecast features): {baseline_ba:.4f}\")\n",
        "        \n",
        "        print(\"\\nImpact of adding feature groups:\")\n",
        "        for ablation in [\"small_features\", \"no_context\", \"no_error_features\"]:\n",
        "            abl_results = results_df[results_df[\"ablation\"] == ablation]\n",
        "            if not abl_results.empty:\n",
        "                abl_ba = abl_results[\"balanced_accuracy\"].mean()\n",
        "                diff = abl_ba - baseline_ba\n",
        "                print(f\"  {ablation}: {abl_ba:.4f} (diff: {diff:+.4f})\")\n",
        "    \n",
        "    # Feature set comparison\n",
        "    print(\"\\nFeature Set Comparison:\")\n",
        "    for fs in [\"small_features\", \"medium_features\"]:\n",
        "        fs_results = results_df[results_df[\"ablation\"] == fs]\n",
        "        if not fs_results.empty:\n",
        "            print(f\"  {fs}: BA={fs_results['balanced_accuracy'].mean():.4f}, Features={fs_results['feature_count'].mean():.0f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "**Experiment 5 Complete!**\n",
        "\n",
        "Next: Run notebook 07 for comprehensive summary across all experiments."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
